{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 300: Itinerary Choice Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, os, pandas as pd\n",
    "import larch.numba as lx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example itinerary choice described here is based on data derived from a ticketing database\n",
    "provided by the Airlines Reporting Corporation. The data represent ten origin destination\n",
    "pairs for travel in U.S. continental markets in May of 2013.   Itinerary characteristics\n",
    "have been masked, e.g., carriers are labeled generically as \"carrier X\" and departure times\n",
    "have been aggregated into categories. A fare is provided but is not completely accurate (a\n",
    "random error has been added to each fare). These modifications were made to satisfy\n",
    "nondisclosure agreements, so that the data can be published freely for teaching and\n",
    "demostration purposes.  It is generally representative of real itinerary choice data used\n",
    "in practice, and the results obtained from this data are intuitive from a behavioral\n",
    "perspective, but it is not quite accurate and should not be used for behavioral studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "In this example we will import the air itinerary choice example dataset, starting from a csv\n",
    "text file in [idca](idca) format.  Suppose that data file is gzipped, named \"arc.csv.gz\" and\n",
    "is located in the current directory (use `os.getcwd` to see what is the\n",
    "current directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "doc_only": true
   },
   "outputs": [],
   "source": [
    "with gzip.open(lx.example_file(\"arc\"), 'rt') as previewfile:\n",
    "    print(*(next(previewfile) for x in range(70)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the file contains column headers. After that, each line represents\n",
    "an alternative available to one or more decision makers. In our sample data, we see the first 67\n",
    "lines of data share a ``id_case`` of 1, indicating that they are 67 different itineraries\n",
    "available to the first decision maker type.  An identidier of the alternatives is given by the\n",
    "number in the column ``id_alt``, although this number is simply a sequential counter within each case\n",
    "in the raw data, and conveys no other information about the itinerary or its attributes.\n",
    "The observed choices of the decision maker[s] are indicated in the column ``choice``.\n",
    "That column counts the number of travelers who face this choice set and chose the itinerary\n",
    "described by this row in the file.\n",
    "\n",
    "We can load this data easily using pandas.  We'll also set the index of the resulting DataFrame to\n",
    "be the case and alt identifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itin = pd.read_csv(lx.example_file(\"arc\"), index_col=['id_case','id_alt'])\n",
    "itin.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = lx.Dataset.from_idca(itin, crack=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "By setting `crack` to `True`, Larch automatically analyzed the data to find variables that do not vary within\n",
    "cases, and transformed those into |idco| format variables.  If you would prefer that\n",
    "Larch not do this you can omit this argument or set it to False.  This is particularly\n",
    "important for larger datasets (the data sample included is only a tiny extract of the data\n",
    "that might be available for this kind of model), as breaking the data into seperate |idca| and |idco| parts is\n",
    "a relatively expensive operation, and it is not actually required for most model structures.\n",
    "\n",
    "Also, you may note that in creating the Dataset object, the set of all \n",
    "possible alternatives was deduced automatically from all the values\n",
    "in the ``altid`` column.  You will note that, while the sample case we have peeked at in the beginning\n",
    "of the raw data file has 67 alternatives, there are other observations in the file with alternatives numbering\n",
    "up to 127.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
