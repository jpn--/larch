{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Larch is (mostly) compatible with the [scikit-learn](https://scikit-learn.org) stucture for machine learning.\n",
    "Within this structure, the larch.Model object can be used as an `estimator`\n",
    "and as a `predictor`.\n",
    "\n",
    "Note this page applies to the legacy interface for Larch.\n",
    "Updates to enable these features for the numba-based version are coming eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Larch within Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "from pytest import approx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larch\n",
    "import pandas as pd\n",
    "from larch import PX, P, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from larch.data_warehouse import example_file\n",
    "df = pd.read_csv(example_file(\"MTCwork.csv.gz\"))\n",
    "df.set_index(['casenum','altnum'], inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the scikit-learn interface, we'll need to define our model\n",
    "based exclusively on idca or idco format data.  We do so here,\n",
    "although we don't need to actually connect the model to the data yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = larch.Model()\n",
    "\n",
    "m.utility_ca = (\n",
    "    PX('tottime') \n",
    "    + PX('totcost') \n",
    "    + sum(P(f'ASC_{i}') * X(f'altnum=={i}') for i in [2,3,4,5,6])\n",
    "    + sum(P(f'HHINC#{i}') * X(f'(altnum=={i})*hhinc') for i in [2,3,4,5,6])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Because the larch.Model object is an estimator, if offers a `fit`\n",
    "method to estimate the fitted (likelihood maximizing) parameters.  This method\n",
    "for model estimation takes a plain old pandas.DataFrame as the `X` input. Because\n",
    "this is a regular DataFrame, the data does not internally identify which column[s]\n",
    "contain the observed choice values, so that data must be explictly identified\n",
    "in the method call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(df, y=df.chose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert m.pvals == approx(np.array([\n",
    "       -2.178014e+00, -3.725078e+00, -6.708610e-01, \n",
    "       -2.376328e+00, -2.067752e-01, -2.169938e-03,  \n",
    "       3.577067e-04,  -5.286324e-03, -1.280798e-02, \n",
    "       -9.686303e-03, -4.920235e-03, -5.134209e-02]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Unlike most scikit-learn estimators, the [fit](larch.Model.fit) method cannot\n",
    "accept a numpy ndarray, because Larch needs the column names to be able \n",
    "to match up the data to the pre-defined utility function.  But we can\n",
    "use the `predict`, `predict_proba` and `score` functions with dataframe inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = m.predict_proba(df)\n",
    "proba.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = m.score(df, y=df.chose)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score * m.dataframes.n_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert score * m.dataframes.n_cases == approx(-3626.1862555129305)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-Learn within Larch\n",
    "\n",
    "It is also possible to use machine learning methods in a chained model with Larch.\n",
    "This can be implemented through a \"prelearning\" step, which builds a predictor\n",
    "using some other machine learning method, and then adding the result of that \n",
    "prediction as an input into the discrete choice model.\n",
    "\n",
    "**Use this power with great care!** Applying a prelearner can result in over-fitting,\n",
    "spoil the interpretability of some or all of the model parameters, and create\n",
    "other challenging problems. Achieving an amazingly good log likelihood is not\n",
    "necessarily a sign that you have a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import larch.prelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = larch.DataFrames(df.drop(columns=['casenum','altnum']), ch='chose', crack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prelearned = larch.prelearning.XGBoostPrelearner(\n",
    "    dfs,\n",
    "    ca_columns=['totcost', 'tottime'],\n",
    "    co_columns=['numveh', 'hhsize', 'hhinc', 'famtype', 'age'],\n",
    "    eval_metric='logloss',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs1 = prelearned.apply(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = larch.Model(dfs1)\n",
    "\n",
    "m.utility_ca = (\n",
    "    PX('tottime') \n",
    "    + PX('totcost') \n",
    "    + PX('prelearned_utility') \n",
    ")\n",
    "m.utility_co[2] = P(\"ASC_SR2\")  + P(\"hhinc#2\") * X(\"hhinc\")\n",
    "m.utility_co[3] = P(\"ASC_SR3P\") + P(\"hhinc#3\") * X(\"hhinc\")\n",
    "m.utility_co[4] = P(\"ASC_TRAN\") + P(\"hhinc#4\") * X(\"hhinc\")\n",
    "m.utility_co[5] = P(\"ASC_BIKE\") + P(\"hhinc#5\") * X(\"hhinc\")\n",
    "m.utility_co[6] = P(\"ASC_WALK\") + P(\"hhinc#6\") * X(\"hhinc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_data()\n",
    "m.loglike()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.maximize_loglike()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
